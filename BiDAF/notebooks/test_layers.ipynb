{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../src/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import model.layers as layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 5\n",
    "HIDDEN_SIZE = 3\n",
    "DROP_PROB = 0.0\n",
    "SEQ_LEN = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `layers.Embedding`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1414,  1.4722,  0.2721, -0.9674, -0.7047, -1.1054],\n",
       "        [-0.8321,  1.0332,  1.0490, -0.0857,  0.7630,  1.4631],\n",
       "        [-2.6773,  0.5008,  0.8457,  0.2306, -0.1543, -0.7707],\n",
       "        [-0.3787,  0.2165, -0.3395, -1.4682,  0.7444,  1.1926],\n",
       "        [-0.6989,  1.9091,  0.1079,  0.6685, -0.1941,  0.0660],\n",
       "        [ 0.9258, -0.5765,  0.7634,  0.3824,  1.1020, -0.0477],\n",
       "        [-0.7579, -1.5932,  2.9906, -0.1598, -1.1834,  0.2845],\n",
       "        [ 0.1882, -0.8804, -1.1744,  0.7914, -0.4334, -0.2785],\n",
       "        [-1.1068, -0.4291, -0.1081,  0.4690,  0.4352, -0.5876],\n",
       "        [-1.4428, -0.5450, -0.5684,  0.6086, -0.2083,  1.4488],\n",
       "        [ 0.1462,  1.6937,  1.0190,  1.5619, -0.2005, -0.2793]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = 11\n",
    "embed_size = 6\n",
    "wordvecs = torch.randn((vocab_size, embed_size))\n",
    "wordvecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(\n",
       "  (embed): Embedding(11, 6)\n",
       "  (proj): Linear(in_features=6, out_features=3, bias=False)\n",
       "  (hwy): HighwayEncoder(\n",
       "    (transforms): ModuleList(\n",
       "      (0): Linear(in_features=3, out_features=3, bias=True)\n",
       "      (1): Linear(in_features=3, out_features=3, bias=True)\n",
       "    )\n",
       "    (gates): ModuleList(\n",
       "      (0): Linear(in_features=3, out_features=3, bias=True)\n",
       "      (1): Linear(in_features=3, out_features=3, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed = layers.Embedding(wordvecs, HIDDEN_SIZE, DROP_PROB)\n",
    "embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  9,  1,  7,  5, 10,  6],\n",
       "        [ 9, 10,  3,  2,  5,  8,  3],\n",
       "        [ 3,  3,  5,  1,  4,  3, 10],\n",
       "        [10,  8, 10, 10,  0,  6, 10],\n",
       "        [ 8,  6,  0,  3,  6,  8,  1]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_len = 7\n",
    "inpt = torch.randint(0, vocab_size, size=(BATCH_SIZE, SEQ_LEN))\n",
    "inpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 7, 6]), torch.Size([5, 7, 3]), torch.Size([5, 7, 3]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    embed_output = embed.embed(inpt)\n",
    "    proj_output = embed.proj(embed_output)\n",
    "    hwy_output = embed.hwy(proj_output)\n",
    "embed_output.shape, proj_output.shape, hwy_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert list(embed_output.shape) == [BATCH_SIZE, SEQ_LEN, embed_size]\n",
    "assert list(proj_output.shape) == [BATCH_SIZE, SEQ_LEN, HIDDEN_SIZE]\n",
    "assert list(hwy_output.shape) == [BATCH_SIZE, SEQ_LEN, HIDDEN_SIZE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.4233,  0.0963, -0.2024],\n",
       "         [-0.0488,  0.2129, -0.1705],\n",
       "         [-0.3025,  0.4297,  0.4915],\n",
       "         [ 0.4233,  0.0963, -0.2024],\n",
       "         [-0.0042,  0.1524,  0.3704],\n",
       "         [ 0.2882,  0.9089,  0.7716],\n",
       "         [-1.3659, -0.3301, -0.6784]],\n",
       "\n",
       "        [[-0.0488,  0.2129, -0.1705],\n",
       "         [ 0.2882,  0.9089,  0.7716],\n",
       "         [-0.2322, -0.2023, -0.0227],\n",
       "         [-0.3450, -0.4699, -0.5621],\n",
       "         [-0.0042,  0.1524,  0.3704],\n",
       "         [ 0.0638, -0.2787, -0.2946],\n",
       "         [-0.2322, -0.2023, -0.0227]],\n",
       "\n",
       "        [[-0.2322, -0.2023, -0.0227],\n",
       "         [-0.2322, -0.2023, -0.0227],\n",
       "         [-0.0042,  0.1524,  0.3704],\n",
       "         [-0.3025,  0.4297,  0.4915],\n",
       "         [ 0.2775,  0.5744,  0.4712],\n",
       "         [-0.2322, -0.2023, -0.0227],\n",
       "         [ 0.2882,  0.9089,  0.7716]],\n",
       "\n",
       "        [[ 0.2882,  0.9089,  0.7716],\n",
       "         [ 0.0638, -0.2787, -0.2946],\n",
       "         [ 0.2882,  0.9089,  0.7716],\n",
       "         [ 0.2882,  0.9089,  0.7716],\n",
       "         [ 0.1193,  0.0700,  0.1444],\n",
       "         [-1.3659, -0.3301, -0.6784],\n",
       "         [ 0.2882,  0.9089,  0.7716]],\n",
       "\n",
       "        [[ 0.0638, -0.2787, -0.2946],\n",
       "         [-1.3659, -0.3301, -0.6784],\n",
       "         [ 0.1193,  0.0700,  0.1444],\n",
       "         [-0.2322, -0.2023, -0.0227],\n",
       "         [-1.3659, -0.3301, -0.6784],\n",
       "         [ 0.0638, -0.2787, -0.2946],\n",
       "         [-0.3025,  0.4297,  0.4915]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    output = embed(inpt)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert list(output.shape) == [BATCH_SIZE, SEQ_LEN, HIDDEN_SIZE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `layers.HighwayEncoder`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HighwayEncoder(\n",
       "  (transforms): ModuleList(\n",
       "    (0): Linear(in_features=3, out_features=3, bias=True)\n",
       "    (1): Linear(in_features=3, out_features=3, bias=True)\n",
       "  )\n",
       "  (gates): ModuleList(\n",
       "    (0): Linear(in_features=3, out_features=3, bias=True)\n",
       "    (1): Linear(in_features=3, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_layers = 2\n",
    "highway = layers.HighwayEncoder(num_layers, HIDDEN_SIZE)\n",
    "highway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.7623,  0.2548, -0.8532],\n",
       "         [-0.6439,  1.2678,  0.1147],\n",
       "         [-1.0045, -0.3908, -0.6559],\n",
       "         [ 0.4075, -1.7423, -1.5121],\n",
       "         [-0.4982,  0.7425, -0.0890],\n",
       "         [-0.4536,  0.8275, -0.2277],\n",
       "         [ 1.0304,  0.0636, -2.3095]],\n",
       "\n",
       "        [[-0.4858,  0.1347, -1.6507],\n",
       "         [ 0.1572,  0.3561,  0.3294],\n",
       "         [-0.1289, -0.8367, -1.1735],\n",
       "         [ 0.1685, -1.1265, -0.5369],\n",
       "         [ 0.4764,  0.0111,  1.6539],\n",
       "         [ 0.8682, -0.5777,  0.9782],\n",
       "         [ 0.0155, -0.3161, -0.4211]],\n",
       "\n",
       "        [[ 0.6981, -1.1824,  0.8674],\n",
       "         [-0.0533,  0.2441, -0.0291],\n",
       "         [ 1.2880, -0.1411, -1.1692],\n",
       "         [-1.5560, -0.1891,  0.5358],\n",
       "         [-1.9611, -0.1812, -0.5768],\n",
       "         [ 0.4714, -0.1694,  0.5322],\n",
       "         [ 0.8916, -0.5556, -0.0128]],\n",
       "\n",
       "        [[-0.6312, -0.0763, -0.5359],\n",
       "         [ 0.5823, -0.9829,  0.9143],\n",
       "         [ 0.4783,  0.0525, -0.7761],\n",
       "         [ 0.0366,  1.2533,  0.6225],\n",
       "         [-0.5989, -0.4228, -0.8854],\n",
       "         [ 0.0836, -0.9991, -0.3214],\n",
       "         [-0.2121, -1.6281, -0.7474]],\n",
       "\n",
       "        [[-0.3550,  0.6391, -1.2809],\n",
       "         [ 0.1650,  1.1566, -0.8114],\n",
       "         [-1.5246,  0.8112, -0.9612],\n",
       "         [ 0.5667,  1.3866, -0.8950],\n",
       "         [ 0.8178, -0.3086, -0.7514],\n",
       "         [-0.3244, -1.4472, -0.9064],\n",
       "         [ 0.9148,  0.4849,  1.1841]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inpt = torch.randn((BATCH_SIZE, SEQ_LEN, HIDDEN_SIZE))\n",
    "inpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.1061,  0.3132, -0.4994],\n",
       "         [-0.2118,  0.8178,  0.1355],\n",
       "         [-0.8197, -0.2709, -0.4870],\n",
       "         [ 0.4071, -1.5224, -1.1336],\n",
       "         [-0.2439,  0.5121, -0.0488],\n",
       "         [-0.2092,  0.5703, -0.1436],\n",
       "         [ 0.8281,  0.0540, -1.3558]],\n",
       "\n",
       "        [[-0.3821,  0.0963, -1.0313],\n",
       "         [ 0.2335,  0.2770,  0.2613],\n",
       "         [-0.1056, -0.6733, -0.8632],\n",
       "         [ 0.1647, -0.9303, -0.4257],\n",
       "         [ 0.5562,  0.0577,  1.4045],\n",
       "         [ 0.8008, -0.4622,  0.8325],\n",
       "         [ 0.0252, -0.2509, -0.3225]],\n",
       "\n",
       "        [[ 0.6569, -0.9875,  0.7496],\n",
       "         [ 0.0318,  0.1861, -0.0222],\n",
       "         [ 1.0667, -0.1238, -0.8322],\n",
       "         [-1.1935, -0.0457,  0.4204],\n",
       "         [-1.5594, -0.0109, -0.3924],\n",
       "         [ 0.4552, -0.1171,  0.4337],\n",
       "         [ 0.7849, -0.4652, -0.0103]],\n",
       "\n",
       "        [[-0.4947, -0.0548, -0.3970],\n",
       "         [ 0.5528, -0.8002,  0.7849],\n",
       "         [ 0.4054,  0.0429, -0.5665],\n",
       "         [ 0.3169,  0.9120,  0.5386],\n",
       "         [-0.4926, -0.3127, -0.6496],\n",
       "         [ 0.0840, -0.8088, -0.2570],\n",
       "         [-0.1662, -1.3313, -0.5953]],\n",
       "\n",
       "        [[-0.2410,  0.4489, -0.8297],\n",
       "         [ 0.2321,  0.8492, -0.5016],\n",
       "         [-1.0783,  0.4903, -0.5876],\n",
       "         [ 0.5261,  1.0561, -0.5245],\n",
       "         [ 0.6868, -0.2637, -0.5637],\n",
       "         [-0.2693, -1.1684, -0.7058],\n",
       "         [ 0.8952,  0.4296,  0.9998]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    output = highway(inpt)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert list(output.shape) == [BATCH_SIZE, SEQ_LEN, HIDDEN_SIZE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:squad] *",
   "language": "python",
   "name": "conda-env-squad-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
